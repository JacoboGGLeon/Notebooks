{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nGraph API\\n\\nLimitations\\nYou can only read a maximum of 100 feed posts with the limit field. \\nIf you try to read more than that you will get an error message to not exceed 100.\\n\\nWhen you use /page-id/tagged to show the posts that tag this page, the results include \\nposts from other pages only if those pages are authentic.\\n\\nThe available user agents allowed for these Graph API calls are subject to change without notice. \\nIf you are experiencing issues, you may want to change to a newer version of your particular user agent.\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Graph API\n",
    "\n",
    "Limitations\n",
    "You can only read a maximum of 100 feed posts with the limit field. \n",
    "If you try to read more than that you will get an error message to not exceed 100.\n",
    "\n",
    "When you use /page-id/tagged to show the posts that tag this page, the results include \n",
    "posts from other pages only if those pages are authentic.\n",
    "\n",
    "The available user agents allowed for these Graph API calls are subject to change without notice. \n",
    "If you are experiencing issues, you may want to change to a newer version of your particular user agent.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Step 0- Harnessing Social Data - Connecting, Capturing, and Cleaning\n",
    "\"\"\"\n",
    "\n",
    "import requests \n",
    "import json\n",
    "from pymongo import MongoClient\n",
    "\n",
    "params = {'access_token': 'EAAE0OPeUvUcBAHr0mJC7rvdzlZAJzP27cZAuSTy2ZAN3wjAeCZAnKjiqLpxBgM8M9o1vUpCkTOzsD4lb4kVZAkuoKynQdVONFVYzZCeKvZBEVIIpfLgUhJRY6TpijFZBSD3mwnTqgZA57JhaUsQZBo8LnkS1aPuC7h8RcZD'}\n",
    "\n",
    "client = MongoClient('localhost:27017')\n",
    "db = client.facebook\n",
    "collection_posts = db.posts\n",
    "collection_comments = db.comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Step 1 – data extraction\n",
    "We will define Facebook endpoints, wich will be used to retrieve the data. \n",
    "\n",
    "In Graph API all the fields have to be explicity specified:\n",
    "    ·id: the Id of the post\n",
    "    ·message: the content of the post\n",
    "    ·reactions: a list of reactions of this post\n",
    "    ·shares: the number of shares\n",
    "    ·from: the author name of the post\n",
    "    ·caption: the caption of the post\n",
    "    ·created_time: a timestap\n",
    "    \n",
    "In the comments_url we defined two fields:\n",
    "    ·filter=stream: to get paginated results\n",
    "    ·limit: the limit of the maximum allowed\n",
    "\"\"\"\n",
    "\n",
    "# first endpoint will be used to extract all the posts:\n",
    "page_url = 'https://graph.facebook.com/v2.8/Google/feed?fields=id,message,reactions,shares,from,caption,created_time,likes.summary(true)'\n",
    "\n",
    "# second endpoint to extract all comments\n",
    "comments_url = 'https://graph.facebook.com/v2.8/{post_id}/comments?filter=stream&limit=100'\n",
    "\n",
    "# Get the first page of posts\n",
    "result = requests.get(page_url, params = params)\n",
    "\n",
    "posts = result.json()\n",
    "\n",
    "# Until the response is not empty (there are more posts in response) try to get all the posts and related comments:\n",
    "while True:\n",
    "    try:\n",
    "    ###Retrieve one post\n",
    "        for element in posts['data']:\n",
    "            collection_posts.insert(element)\n",
    "            ####Retrieve all comments for this post\n",
    "            this_comment_url = comments_url.replace(\"{post_id}\",element['id'])\n",
    "            comments = requests.get(this_comment_url, params = params).json()\n",
    "            \n",
    "            #loop through all comments until the response is empty (there are no more comments)\n",
    "            while ('paging' in comments and 'cursors' in comments['paging'] and 'after' in comments['paging']['cursors']):\n",
    "                ###Iterate through all comments\n",
    "                for comment in comments['data']:\n",
    "                    comment['post_id'] = element['id']\n",
    "                    collection_comments.insert(comment)\n",
    "                \n",
    "                comments = requests.get(this_comment_url + '&after=' + comments['paging']['cursors']['after'], params = params).json()\n",
    " \n",
    "        ####Go to the next page in feed\n",
    "        posts = requests.get(posts['paging']['next']).json()\n",
    "    except (KeyError, e):\n",
    "        print(e)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "posts_data = [] \n",
    "comments_data = [] \n",
    "\n",
    "for doc in collection_posts.find({}): \n",
    "    try: \n",
    "        posts_data.append((doc['message'],doc['created_time'],doc['likes']['summary']['total_count'],doc['shares']['count'],doc['id'])) \n",
    "    except: \n",
    "#        print(\"No message\") \n",
    "        pass\n",
    "    \n",
    "for comment in collection_comments.find({}): \n",
    "    try: \n",
    "        comments_data.append((comment['message'],comment['created_time'],comment['post_id'])) \n",
    "    except: \n",
    "        pass\n",
    "    \n",
    "#create dataframes\n",
    "df_posts = pd.DataFrame(posts_data) \n",
    "df_posts.columns = ['message','created_time','likes','shares','post_id'] \n",
    "df_comments = pd.DataFrame(comments_data) \n",
    "df_comments.columns = ['message','created_time','post_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row:  2425  col:  5\n",
      "row:  659119  col:  3\n"
     ]
    }
   ],
   "source": [
    "print(\"row: \", df_posts.shape[0], \" col: \", df_posts.shape[1])\n",
    "print(\"row: \", df_comments.shape[0], \" col: \", df_comments.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
